{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn2pmml import PMMLPipeline, sklearn2pmml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load local datafile with 123,419 reviews containing text and sentiment (0,1) from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('5_4_3_all_data.csv', header = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display dataframe head and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no problem with constant improvement i switche...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i live  minutes away from the nearest branch a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am very annoyed with this app i do like bein...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont see how so many people on the reviews c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you can do almost every function the full site...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  no problem with constant improvement i switche...          1\n",
       "1  i live  minutes away from the nearest branch a...          1\n",
       "2  i am very annoyed with this app i do like bein...          0\n",
       "3  i dont see how so many people on the reviews c...          1\n",
       "4  you can do almost every function the full site...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i live  minutes away from the nearest branch and this app lets me do basically all of my banking  the main reason i stopped using local banks was lack of overdraft protection which unfortunately was a problem for my wife and i until she landed a decent paying job  being over drafted for bills should say we were having financial trouble but not allowing us the opportunity to deposit cash i made from tips the night before to catch it up and instead charging a painful  dollar fee was killing me  chase offers overdraft protection so it became a no brainer even though i live almost an hour away from the nearest branch  even considering this distance i usually dont have to worry about depositing cash or withdrawals just my paycheck being deposited which this app does beautifully and quickly with zero hassle  i can view my statements and every transaction quickly  it got old typing in my password all the time but since they added the finger print login its gold  i also have the security of knowing i should have a nearby branch almost anywhere we move when my wife and i finish school and hopefully get better jobs chase wont have to worry about us switching banks if they keep this level of service up and avoid punishment fees that kick the small man while hes down \n",
      "(123419, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df['review'][1])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign the review text and the sentiment to separate input and label dataframes, then assign the raw values to X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_X = df['review']\n",
    "label_Y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = input_X.values\n",
    "Y = label_Y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a CountVectorizer object using Sklearn's CountVectorizer\n",
    "###### After creating the CountVectorizer object, we perform a fit and transform on our input_X in a single method call. The transform uses the CountVectorizer algorithm to convert our review data that is held in our input_X into a document term matrix. Next we use a fit to learn a dictionary of all of the transformed tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total time to fit_transform CountVectorizer :', 3.961841106414795)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "vect = CountVectorizer(min_df = 1, max_features = 900)\n",
    "X = vect.fit_transform(X)\n",
    "toc = time.time()\n",
    "print(\"Total time to fit_transform CountVectorizer :\", (toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Logistic Regression Model using Sklearn's Linear Model Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total time in seconds elapsed :', 1.4745359420776367)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "model.fit(X, Y)\n",
    "toc = time.time()\n",
    "print(\"Total time to fit Logistic Regression Model :\", (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a PMML Pipeline object and add the Logistic Regression to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total time in seconds elapsed :', 0.0005259513854980469)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "myPMMLPipeline = PMMLPipeline([\n",
    "    (\"classifier\", model)\n",
    "])\n",
    "toc = time.time()\n",
    "print(\"Total time to build PMML Pipeline :\", (toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export PMML Pipeline with Logistic Regression model to .pmml file for use in SparkML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total time in seconds elapsed :', 1.479334831237793)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "sklearn2pmml(myPMMLPipeline, \"LogisticRegressionCountVectorizerModel.pmml\", with_repr = True)\n",
    "toc = time.time()\n",
    "print(\"Total time to convert Sklearn to PMML :\", (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction\n",
    "### First we will use our CountVectorizer on a single review randomly pulled from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "singleReview = [\"i love this app  it keeps me up to date on how much and what is in my acct i could never be without this app after having had it  i have been blessed to never once had a problem so far and ive been using it for around six months now  im never giving it up\"]\n",
    "vectorizedSentence = vect.transform(singleReview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the transformed review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 4 1 1 1 1 1 1 1 3 1 1 1 1 1 2 2 2 1\n",
      " 1 1]\n",
      "[ 10  20  42  53  60  85  89 172 184 266 290 317 330 346 348 363 372 383\n",
      " 399 403 406 411 456 473 487 494 498 510 519 530 531 592 696 767 781 820\n",
      " 835 861 878]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizedSentence.data)\n",
    "print(vectorizedSentence.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction on the vectorized review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07459858  0.92540142]]\n"
     ]
    }
   ],
   "source": [
    "print(myPMMLPipeline.predict_proba(vectorizedSentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model to Pickle and Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = open(\"pickleFile.pkl\", 'wb')\n",
    "pickle.dump(model, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joblibLRModel.sav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_file = \"joblibLRModel.sav\"\n",
    "joblib.dump(model,joblib_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
